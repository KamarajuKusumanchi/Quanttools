{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Visualizing the stock market structure\n",
    "\n",
    "\n",
    "This example employs several unsupervised learning techniques to extract\n",
    "the stock market structure from variations in historical quotes.\n",
    "\n",
    "The quantity that we use is the daily variation in quote price: quotes\n",
    "that are linked tend to cofluctuate during a day.\n",
    "\n",
    "\n",
    "Learning a graph structure\n",
    "--------------------------\n",
    "\n",
    "We use sparse inverse covariance estimation to find which quotes are\n",
    "correlated conditionally on the others. Specifically, sparse inverse\n",
    "covariance gives us a graph, that is a list of connection. For each\n",
    "symbol, the symbols that it is connected too are those useful to explain\n",
    "its fluctuations.\n",
    "\n",
    "Clustering\n",
    "----------\n",
    "\n",
    "We use clustering to group together quotes that behave similarly. Here,\n",
    "amongst the `various clustering techniques <clustering>` available\n",
    "in the scikit-learn, we use `affinity_propagation` as it does\n",
    "not enforce equal-size clusters, and it can choose automatically the\n",
    "number of clusters from the data.\n",
    "\n",
    "Note that this gives us a different indication than the graph, as the\n",
    "graph reflects conditional relations between variables, while the\n",
    "clustering reflects marginal properties: variables clustered together can\n",
    "be considered as having a similar impact at the level of the full stock\n",
    "market.\n",
    "\n",
    "Embedding in 2D space\n",
    "---------------------\n",
    "\n",
    "For visualization purposes, we need to lay out the different symbols on a\n",
    "2D canvas. For this we use `manifold` techniques to retrieve 2D\n",
    "embedding.\n",
    "\n",
    "\n",
    "Visualization\n",
    "-------------\n",
    "\n",
    "The output of the 3 models are combined in a 2D graph where nodes\n",
    "represents the stocks and edges the:\n",
    "\n",
    "- cluster labels are used to define the color of the nodes\n",
    "- the sparse covariance model is used to display the strength of the edges\n",
    "- the 2D embedding is used to position the nodes in the plan\n",
    "\n",
    "This example has a fair amount of visualization-related code, as\n",
    "visualization is crucial here to display the graph. One of the challenge\n",
    "is to position the labels minimizing overlap. For this we use an\n",
    "heuristic based on the direction of the nearest neighbor along each\n",
    "axis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching quote history for 'AAPL'\n",
      "Fetching quote history for 'AIG'\n",
      "Fetching quote history for 'AMZN'\n",
      "Fetching quote history for 'AXP'\n",
      "Fetching quote history for 'BA'\n",
      "Fetching quote history for 'BAC'\n",
      "Fetching quote history for 'CAJ'\n",
      "Fetching quote history for 'CAT'\n",
      "Fetching quote history for 'CL'\n",
      "Fetching quote history for 'CMCSA'\n",
      "Fetching quote history for 'COP'\n",
      "Fetching quote history for 'CSCO'\n",
      "Fetching quote history for 'CVC'\n",
      "Fetching quote history for 'CVS'\n",
      "Fetching quote history for 'CVX'\n",
      "Fetching quote history for 'DD'\n",
      "Fetching quote history for 'DELL'\n",
      "Fetching quote history for 'F'\n",
      "Fetching quote history for 'GD'\n",
      "Fetching quote history for 'GE'\n",
      "Fetching quote history for 'GM'\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-a9e6253474cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     98\u001b[0m            'master/financial-data/{}.csv')\n\u001b[0;32m     99\u001b[0m     data = list(csv.DictReader(l.decode('utf8')\n\u001b[1;32m--> 100\u001b[1;33m                                for l in urlopen(url.format(symbol))))\n\u001b[0m\u001b[0;32m    101\u001b[0m     quotes.append({'close': [float(rec['close']) for rec in data],\n\u001b[0;32m    102\u001b[0m                    'open': [float(rec['open']) for rec in data]})\n",
      "\u001b[1;32mC:\\Users\\lizhi\\Anaconda2\\lib\\urllib2.pyc\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\lizhi\\Anaconda2\\lib\\urllib2.pyc\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\lizhi\\Anaconda2\\lib\\urllib2.pyc\u001b[0m in \u001b[0;36mhttp_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m             response = self.parent.error(\n\u001b[1;32m--> 548\u001b[1;33m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[0;32m    549\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\lizhi\\Anaconda2\\lib\\urllib2.pyc\u001b[0m in \u001b[0;36merror\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    471\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'default'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'http_error_default'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    475\u001b[0m \u001b[1;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\lizhi\\Anaconda2\\lib\\urllib2.pyc\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    405\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 407\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    408\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\lizhi\\Anaconda2\\lib\\urllib2.pyc\u001b[0m in \u001b[0;36mhttp_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 556\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_full_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "# Author: Gael Varoquaux gael.varoquaux@normalesup.org\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import csv\n",
    "\n",
    "from sklearn.externals.six.moves.urllib.request import urlopen\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "from sklearn import cluster, covariance, manifold\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "# Retrieve the data from Internet\n",
    "\n",
    "# The data is from 2003 - 2008. This is reasonably calm: (not too long ago so\n",
    "# that we get high-tech firms, and before the 2008 crash). This kind of\n",
    "# historical data can be obtained for from APIs like the quandl.com and\n",
    "# alphavantage.co ones.\n",
    "start_date = datetime(2003, 1, 1).date()\n",
    "end_date = datetime(2008, 1, 1).date()\n",
    "\n",
    "symbol_dict = {\n",
    "    'TOT': 'Total',\n",
    "    'XOM': 'Exxon',\n",
    "    'CVX': 'Chevron',\n",
    "    'COP': 'ConocoPhillips',\n",
    "    'VLO': 'Valero Energy',\n",
    "    'MSFT': 'Microsoft',\n",
    "    'IBM': 'IBM',\n",
    "    'TWX': 'Time Warner',\n",
    "    'CMCSA': 'Comcast',\n",
    "    'CVC': 'Cablevision',\n",
    "    'YHOO': 'Yahoo',\n",
    "    'DELL': 'Dell',\n",
    "    'HPQ': 'HP',\n",
    "    'AMZN': 'Amazon',\n",
    "    'TM': 'Toyota',\n",
    "    'CAJ': 'Canon',\n",
    "    'SNE': 'Sony',\n",
    "    'F': 'Ford',\n",
    "    'HMC': 'Honda',\n",
    "    'NAV': 'Navistar',\n",
    "    'NOC': 'Northrop Grumman',\n",
    "    'BA': 'Boeing',\n",
    "    'KO': 'Coca Cola',\n",
    "    'MMM': '3M',\n",
    "    'MCD': 'McDonald\\'s',\n",
    "    'PEP': 'Pepsi',\n",
    "    'K': 'Kellogg',\n",
    "    'UN': 'Unilever',\n",
    "    'MAR': 'Marriott',\n",
    "    'PG': 'Procter Gamble',\n",
    "    'CL': 'Colgate-Palmolive',\n",
    "    'GE': 'General Electrics',\n",
    "    'WFC': 'Wells Fargo',\n",
    "    'JPM': 'JPMorgan Chase',\n",
    "    'AIG': 'AIG',\n",
    "    'AXP': 'American express',\n",
    "    'BAC': 'Bank of America',\n",
    "    'GS': 'Goldman Sachs',\n",
    "    'AAPL': 'Apple',\n",
    "    'SAP': 'SAP',\n",
    "    'CSCO': 'Cisco',\n",
    "    'TXN': 'Texas Instruments',\n",
    "    'XRX': 'Xerox',\n",
    "    'WMT': 'Wal-Mart',\n",
    "    'HD': 'Home Depot',\n",
    "    'GSK': 'GlaxoSmithKline',\n",
    "    'PFE': 'Pfizer',\n",
    "    'SNY': 'Sanofi-Aventis',\n",
    "    'NVS': 'Novartis',\n",
    "    'KMB': 'Kimberly-Clark',\n",
    "    'R': 'Ryder',\n",
    "    'GD': 'General Dynamics',\n",
    "    'RTN': 'Raytheon',\n",
    "    'CVS': 'CVS',\n",
    "    'CAT': 'Caterpillar',\n",
    "    'DD': 'DuPont de Nemours',\n",
    "    'TSLA': 'Tesla',\n",
    "    'GM': 'General Motors'}\n",
    "\n",
    "\n",
    "symbols, names = np.array(sorted(symbol_dict.items())).T\n",
    "\n",
    "quotes = []\n",
    "\n",
    "for symbol in symbols:\n",
    "    print('Fetching quote history for %r' % symbol, file=sys.stderr)\n",
    "    url = ('https://raw.githubusercontent.com/scikit-learn/examples-data/'\n",
    "           'master/financial-data/{}.csv')\n",
    "    data = list(csv.DictReader(l.decode('utf8')\n",
    "                               for l in urlopen(url.format(symbol))))\n",
    "    quotes.append({'close': [float(rec['close']) for rec in data],\n",
    "                   'open': [float(rec['open']) for rec in data]})\n",
    "\n",
    "close_prices = np.vstack([q['close'] for q in quotes])\n",
    "open_prices = np.vstack([q['open'] for q in quotes])\n",
    "\n",
    "# The daily variations of the quotes are what carry most information\n",
    "variation = close_prices - open_prices\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "# Learn a graphical structure from the correlations\n",
    "edge_model = covariance.GraphLassoCV()\n",
    "\n",
    "# standardize the time series: using correlations rather than covariance\n",
    "# is more efficient for structure recovery\n",
    "X = variation.copy().T\n",
    "X /= X.std(axis=0)\n",
    "edge_model.fit(X)\n",
    "\n",
    "# #############################################################################\n",
    "# Cluster using affinity propagation\n",
    "\n",
    "_, labels = cluster.affinity_propagation(edge_model.covariance_)\n",
    "n_labels = labels.max()\n",
    "\n",
    "for i in range(n_labels + 1):\n",
    "    print('Cluster %i: %s' % ((i + 1), ', '.join(names[labels == i])))\n",
    "\n",
    "# #############################################################################\n",
    "# Find a low-dimension embedding for visualization: find the best position of\n",
    "# the nodes (the stocks) on a 2D plane\n",
    "\n",
    "# We use a dense eigen_solver to achieve reproducibility (arpack is\n",
    "# initiated with random vectors that we don't control). In addition, we\n",
    "# use a large number of neighbors to capture the large-scale structure.\n",
    "node_position_model = manifold.LocallyLinearEmbedding(\n",
    "    n_components=2, eigen_solver='dense', n_neighbors=6)\n",
    "\n",
    "embedding = node_position_model.fit_transform(X.T).T\n",
    "\n",
    "# #############################################################################\n",
    "# Visualization\n",
    "plt.figure(1, facecolor='w', figsize=(10, 8))\n",
    "plt.clf()\n",
    "ax = plt.axes([0., 0., 1., 1.])\n",
    "plt.axis('off')\n",
    "\n",
    "# Display a graph of the partial correlations\n",
    "partial_correlations = edge_model.precision_.copy()\n",
    "d = 1 / np.sqrt(np.diag(partial_correlations))\n",
    "partial_correlations *= d\n",
    "partial_correlations *= d[:, np.newaxis]\n",
    "non_zero = (np.abs(np.triu(partial_correlations, k=1)) > 0.02)\n",
    "\n",
    "# Plot the nodes using the coordinates of our embedding\n",
    "plt.scatter(embedding[0], embedding[1], s=100 * d ** 2, c=labels,\n",
    "            cmap=plt.cm.nipy_spectral)\n",
    "\n",
    "# Plot the edges\n",
    "start_idx, end_idx = np.where(non_zero)\n",
    "# a sequence of (*line0*, *line1*, *line2*), where::\n",
    "#            linen = (x0, y0), (x1, y1), ... (xm, ym)\n",
    "segments = [[embedding[:, start], embedding[:, stop]]\n",
    "            for start, stop in zip(start_idx, end_idx)]\n",
    "values = np.abs(partial_correlations[non_zero])\n",
    "lc = LineCollection(segments,\n",
    "                    zorder=0, cmap=plt.cm.hot_r,\n",
    "                    norm=plt.Normalize(0, .7 * values.max()))\n",
    "lc.set_array(values)\n",
    "lc.set_linewidths(15 * values)\n",
    "ax.add_collection(lc)\n",
    "\n",
    "# Add a label to each node. The challenge here is that we want to\n",
    "# position the labels to avoid overlap with other labels\n",
    "for index, (name, label, (x, y)) in enumerate(\n",
    "        zip(names, labels, embedding.T)):\n",
    "\n",
    "    dx = x - embedding[0]\n",
    "    dx[index] = 1\n",
    "    dy = y - embedding[1]\n",
    "    dy[index] = 1\n",
    "    this_dx = dx[np.argmin(np.abs(dy))]\n",
    "    this_dy = dy[np.argmin(np.abs(dx))]\n",
    "    if this_dx > 0:\n",
    "        horizontalalignment = 'left'\n",
    "        x = x + .002\n",
    "    else:\n",
    "        horizontalalignment = 'right'\n",
    "        x = x - .002\n",
    "    if this_dy > 0:\n",
    "        verticalalignment = 'bottom'\n",
    "        y = y + .002\n",
    "    else:\n",
    "        verticalalignment = 'top'\n",
    "        y = y - .002\n",
    "    plt.text(x, y, name, size=10,\n",
    "             horizontalalignment=horizontalalignment,\n",
    "             verticalalignment=verticalalignment,\n",
    "             bbox=dict(facecolor='w',\n",
    "                       edgecolor=plt.cm.nipy_spectral(label / float(n_labels)),\n",
    "                       alpha=.6))\n",
    "\n",
    "plt.xlim(embedding[0].min() - .15 * embedding[0].ptp(),\n",
    "         embedding[0].max() + .10 * embedding[0].ptp(),)\n",
    "plt.ylim(embedding[1].min() - .03 * embedding[1].ptp(),\n",
    "         embedding[1].max() + .03 * embedding[1].ptp())\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
